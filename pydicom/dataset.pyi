import numpy
import os
from _typeshed import Incomplete
from collections.abc import Callable as Callable, Iterator, MutableSequence, Set as Set, ValuesView
from pydicom import config as config, jsonrep as jsonrep
from pydicom._version import __version_info__ as __version_info__
from pydicom.charset import convert_encodings as convert_encodings, default_encoding as default_encoding
from pydicom.config import logger as logger
from pydicom.datadict import dictionary_VR as dictionary_VR, dictionary_description as dictionary_description, get_private_entry as get_private_entry, keyword_for_tag as keyword_for_tag, repeater_has_keyword as repeater_has_keyword, tag_for_keyword as tag_for_keyword
from pydicom.dataelem import DataElement as DataElement, DataElement_from_raw as DataElement_from_raw, RawDataElement as RawDataElement
from pydicom.filebase import ReadableBuffer as ReadableBuffer, WriteableBuffer as WriteableBuffer
from pydicom.fileutil import PathType as PathType, path_from_pathlike as path_from_pathlike
from pydicom.misc import warn_and_log as warn_and_log
from pydicom.pixels import compress as compress, convert_color_space as convert_color_space, decompress as decompress, pixel_array as pixel_array
from pydicom.pixels.utils import get_image_pixel_ids as get_image_pixel_ids, reshape_pixel_array as reshape_pixel_array
from pydicom.tag import BaseTag as BaseTag, TAG_PIXREP as TAG_PIXREP, Tag as Tag, TagType as TagType, tag_in_exception as tag_in_exception
from pydicom.uid import PYDICOM_IMPLEMENTATION_UID as PYDICOM_IMPLEMENTATION_UID, UID as UID
from pydicom.valuerep import AMBIGUOUS_VR as AMBIGUOUS_VR
from types import TracebackType
from typing import Any, AnyStr, BinaryIO, overload

PIXEL_KEYWORDS: Incomplete

class PrivateBlock:
    group: Incomplete
    private_creator: Incomplete
    dataset: Incomplete
    block_start: Incomplete
    def __init__(self, key: tuple[int, str], dataset: Dataset, private_creator_element: int) -> None: ...
    def get_tag(self, element_offset: int) -> BaseTag: ...
    def __contains__(self, element_offset: int) -> bool: ...
    def __getitem__(self, element_offset: int) -> DataElement: ...
    def __delitem__(self, element_offset: int) -> None: ...
    def add_new(self, element_offset: int, VR: str, value: object) -> None: ...
    def __deepcopy__(self, memo: Any) -> PrivateBlock: ...

class Dataset:
    indent_chars: str
    is_decompressed: bool
    is_undefined_length_sequence_item: bool
    file_meta: Incomplete
    def __init__(self, *args: _DatasetType, **kwargs: Any) -> None: ...
    def __enter__(self) -> Dataset: ...
    def __exit__(self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None) -> bool | None: ...
    def add(self, data_element: DataElement) -> None: ...
    def add_new(self, tag: TagType, VR: str, value: Any) -> None: ...
    def add_new_private(self, private_creator: str, group: int, element_offset: int, value: Any, vr: str | None = None) -> None: ...
    def __array__(self) -> numpy.ndarray: ...
    def data_element(self, name: str) -> DataElement | None: ...
    def __contains__(self, name: TagType) -> bool: ...
    def decode(self) -> None: ...
    def copy(self) -> Dataset: ...
    def __delattr__(self, name: str) -> None: ...
    def __delitem__(self, key: slice | BaseTag | TagType) -> None: ...
    def __dir__(self) -> list[str]: ...
    def dir(self, *filters: str) -> list[str]: ...
    def __eq__(self, other: Any) -> bool: ...
    @overload
    def get(self, key: str, default: Any | None = None) -> Any: ...
    @overload
    def get(self, key: int | tuple[int, int] | BaseTag, default: Any | None = None) -> DataElement: ...
    def items(self) -> Set[tuple[BaseTag, _DatasetValue]]: ...
    def keys(self) -> Set[BaseTag]: ...
    def values(self) -> ValuesView[_DatasetValue]: ...
    def __getattr__(self, name: str) -> Any: ...
    @property
    def original_character_set(self) -> str | MutableSequence[str]: ...
    @property
    def read_encoding(self) -> str | MutableSequence[str]: ...
    @read_encoding.setter
    def read_encoding(self, value: str | MutableSequence[str]) -> None: ...
    @overload
    def __getitem__(self, key: slice) -> Dataset: ...
    @overload
    def __getitem__(self, key: TagType) -> DataElement: ...
    def private_block(self, group: int, private_creator: str, create: bool = False) -> PrivateBlock: ...
    def private_creators(self, group: int) -> list[str]: ...
    def get_private_item(self, group: int, element_offset: int, private_creator: str) -> DataElement: ...
    @overload
    def get_item(self, key: slice, *, keep_deferred: bool = ...) -> Dataset: ...
    @overload
    def get_item(self, key: TagType, *, keep_deferred: bool = ...) -> DataElement: ...
    @property
    def is_implicit_VR(self) -> bool | None: ...
    @is_implicit_VR.setter
    def is_implicit_VR(self, value: bool | None) -> None: ...
    @property
    def is_little_endian(self) -> bool | None: ...
    @is_little_endian.setter
    def is_little_endian(self, value: bool | None) -> None: ...
    @property
    def is_original_encoding(self) -> bool: ...
    @property
    def original_encoding(self) -> tuple[bool, bool] | tuple[None, None]: ...
    def set_original_encoding(self, is_implicit_vr: bool | None, is_little_endian: bool | None, character_encoding: str | MutableSequence[str] | None = None) -> None: ...
    def group_dataset(self, group: int) -> Dataset: ...
    def __iter__(self) -> Iterator[DataElement]: ...
    def elements(self) -> Iterator[DataElement | RawDataElement]: ...
    def __len__(self) -> int: ...
    def __ne__(self, other: Any) -> bool: ...
    def clear(self) -> None: ...
    def pop(self, key: BaseTag | TagType, *args: Any) -> _DatasetValue: ...
    def popitem(self) -> tuple[BaseTag, _DatasetValue]: ...
    def setdefault(self, key: TagType, default: Any | None = None) -> DataElement: ...
    def convert_pixel_data(self, handler_name: str = '') -> None: ...
    def compress(self, transfer_syntax_uid: str, arr: numpy.ndarray | None = None, encoding_plugin: str = '', encapsulate_ext: bool = False, *, new_instance_uid: bool = True, jls_error: int | None = None, j2k_cr: list[float] | None = None, j2k_psnr: list[float] | None = None, **kwargs: Any) -> None: ...
    def decompress(self, handler_name: str = '', *, as_rgb: bool = True, new_instance_uid: bool = True, decoding_plugin: str = '', **kwargs: Any) -> None: ...
    def overlay_array(self, group: int) -> numpy.ndarray: ...
    @property
    def pixel_array(self) -> numpy.ndarray: ...
    def pixel_array_options(self, *, index: int | None = None, raw: bool = False, decoding_plugin: str = '', use_v2_backend: bool = False, **kwargs: Any) -> None: ...
    def waveform_array(self, index: int) -> numpy.ndarray: ...
    default_element_format: str
    default_sequence_element_format: str
    def formatted_lines(self, element_format: str = ..., sequence_element_format: str = ..., indent_format: str | None = None) -> Iterator[str]: ...
    @property
    def read_implicit_vr(self) -> bool | None: ...
    @property
    def read_little_endian(self) -> bool | None: ...
    def remove_private_tags(self) -> None: ...
    def save_as(self, filename: str | os.PathLike[AnyStr] | BinaryIO | WriteableBuffer, __write_like_original: bool | None = None, /, *, implicit_vr: bool | None = None, little_endian: bool | None = None, enforce_file_format: bool = False, **kwargs: Any) -> None: ...
    def ensure_file_meta(self) -> None: ...
    def __setattr__(self, name: str, value: Any) -> None: ...
    def __setitem__(self, key: slice | TagType, elem: _DatasetValue) -> None: ...
    def top(self) -> str: ...
    def trait_names(self) -> list[str]: ...
    def update(self, d: _DatasetType) -> None: ...
    def iterall(self) -> Iterator[DataElement]: ...
    def walk(self, callback: Callable[[Dataset, DataElement], None], recursive: bool = True) -> None: ...
    @classmethod
    def from_json(cls, json_dataset: dict[str, Any] | str | bytes | bytearray, bulk_data_uri_handler: Callable[[str, str, str], None | str | int | float | bytes] | Callable[[str], None | str | int | float | bytes] | None = None) -> Dataset: ...
    def to_json_dict(self, bulk_data_threshold: int = 1024, bulk_data_element_handler: Callable[[DataElement], str] | None = None, suppress_invalid_tags: bool = False) -> dict[str, Any]: ...
    def to_json(self, bulk_data_threshold: int = 1024, bulk_data_element_handler: Callable[[DataElement], str] | None = None, dump_handler: Callable[[dict[str, Any]], str] | None = None, suppress_invalid_tags: bool = False) -> str: ...

class FileDataset(Dataset):
    preamble: Incomplete
    file_meta: Incomplete
    fileobj_type: Incomplete
    filename: str
    timestamp: Incomplete
    def __init__(self, filename_or_obj: PathType | BinaryIO | ReadableBuffer, dataset: _DatasetType, preamble: bytes | None = None, file_meta: FileMetaDataset | None = None, is_implicit_VR: bool = True, is_little_endian: bool = True) -> None: ...
    def __copy__(self) -> FileDataset: ...
    def __deepcopy__(self, _: dict[int, Any] | None) -> FileDataset: ...

def validate_file_meta(file_meta: FileMetaDataset, enforce_standard: bool = True) -> None: ...

class FileMetaDataset(Dataset):
    FileMetaInformationGroupLength: Incomplete
    FileMetaInformationVersion: Incomplete
    MediaStorageSOPClassUID: Incomplete
    MediaStorageSOPInstanceUID: Incomplete
    TransferSyntaxUID: Incomplete
    ImplementationClassUID: Incomplete
    ImplementationVersionName: Incomplete
    SourceApplicationEntityTitle: Incomplete
    SendingApplicationEntityTitle: Incomplete
    ReceivingApplicationEntityTitle: Incomplete
    SourcePresentationAddress: Incomplete
    ReceivingPresentationAddress: Incomplete
    PrivateInformationCreatorUID: Incomplete
    PrivateInformation: Incomplete
    def __init__(self, *args: _DatasetType, **kwargs: Any) -> None: ...
    @staticmethod
    def validate(init_value: _DatasetType) -> None: ...
    def __setitem__(self, key: slice | TagType, value: _DatasetValue) -> None: ...
